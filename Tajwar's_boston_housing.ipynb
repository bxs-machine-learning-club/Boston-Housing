{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tajwar's boston_housing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bxs-machine-learning-club/Boston-Housing/blob/master/Tajwar's_boston_housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTY5bHc4puAK",
        "colab_type": "text"
      },
      "source": [
        "Required imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu1jBa68oNFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "6a5c2932-39b5-472a-ecb2-469886045245"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import scale\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkpkcrybp49D",
        "colab_type": "text"
      },
      "source": [
        "Data reading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbvMjip_p-vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#YOUR CODE HERE -- Load boston housing data\n",
        "df = load_boston()\n",
        "#YOUR CODE HERE -- Scale features and targets so that they are btwn 0 and 1\n",
        "x_scaled = scale(df.data)\n",
        "y_scaled = scale(df.target)\n",
        "#YOUR CODE HERE -- Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3ufNxyztQyU",
        "colab_type": "text"
      },
      "source": [
        "Building the sequential model\n",
        "\n",
        "Reference:\n",
        "https://keras.io/models/sequential/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmvMi2ratUGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    #Input layer - 20 nodes, relu activation, 13 features as input_dim\n",
        "    Dense(20, activation=\"relu\", input_dim=13),\n",
        "    #YOUR CODE HERE - Hidden layer (activation = relu)\n",
        "    Dense(40, activation=\"relu\"),\n",
        "    #YOUR CODE HERE - Output layer (activation = linear)\n",
        "    Dense(1, activation=\"linear\"),\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1EMsLVfua2j",
        "colab_type": "text"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEVU53cTuZq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "334bf7c0-b475-4a94-b52f-63bb2a6d975e"
      },
      "source": [
        "#YOUR CODE HERE - Compile the model with Loss = MSE, Optimizer = Adam, Metrics = [MSE, MAE]\n",
        "model.compile(optimizer = 'rmsprop',\n",
        "              loss = 'mse'\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm285uJuvvxP",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdkV5cj5v2Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d34842c-2e17-4bfd-c0a5-2d3c17f1ef75"
      },
      "source": [
        "#YOUR CODE HERE - Train the model with 1000 epochs and a validation split of 0.2\n",
        "h = model.fit(x_train, y_train, epochs = 100, validation_data=(x_test,y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 379 samples, validate on 127 samples\n",
            "Epoch 1/100\n",
            "379/379 [==============================] - 0s 82us/step - loss: 0.0418 - val_loss: 0.1530\n",
            "Epoch 2/100\n",
            "379/379 [==============================] - 0s 59us/step - loss: 0.0412 - val_loss: 0.1526\n",
            "Epoch 3/100\n",
            "379/379 [==============================] - 0s 48us/step - loss: 0.0414 - val_loss: 0.1599\n",
            "Epoch 4/100\n",
            "379/379 [==============================] - 0s 56us/step - loss: 0.0411 - val_loss: 0.1514\n",
            "Epoch 5/100\n",
            "379/379 [==============================] - 0s 70us/step - loss: 0.0395 - val_loss: 0.1520\n",
            "Epoch 6/100\n",
            "379/379 [==============================] - 0s 55us/step - loss: 0.0388 - val_loss: 0.1544\n",
            "Epoch 7/100\n",
            "379/379 [==============================] - 0s 48us/step - loss: 0.0405 - val_loss: 0.1527\n",
            "Epoch 8/100\n",
            "379/379 [==============================] - 0s 67us/step - loss: 0.0410 - val_loss: 0.1651\n",
            "Epoch 9/100\n",
            "379/379 [==============================] - 0s 65us/step - loss: 0.0403 - val_loss: 0.1549\n",
            "Epoch 10/100\n",
            "379/379 [==============================] - 0s 68us/step - loss: 0.0380 - val_loss: 0.1502\n",
            "Epoch 11/100\n",
            "379/379 [==============================] - 0s 52us/step - loss: 0.0386 - val_loss: 0.1578\n",
            "Epoch 12/100\n",
            "379/379 [==============================] - 0s 64us/step - loss: 0.0392 - val_loss: 0.1600\n",
            "Epoch 13/100\n",
            "379/379 [==============================] - 0s 82us/step - loss: 0.0388 - val_loss: 0.1531\n",
            "Epoch 14/100\n",
            "379/379 [==============================] - 0s 58us/step - loss: 0.0382 - val_loss: 0.1544\n",
            "Epoch 15/100\n",
            "379/379 [==============================] - 0s 55us/step - loss: 0.0367 - val_loss: 0.1545\n",
            "Epoch 16/100\n",
            "379/379 [==============================] - 0s 59us/step - loss: 0.0382 - val_loss: 0.1539\n",
            "Epoch 17/100\n",
            "379/379 [==============================] - 0s 77us/step - loss: 0.0373 - val_loss: 0.1534\n",
            "Epoch 18/100\n",
            "379/379 [==============================] - 0s 51us/step - loss: 0.0386 - val_loss: 0.1574\n",
            "Epoch 19/100\n",
            "379/379 [==============================] - 0s 52us/step - loss: 0.0361 - val_loss: 0.1569\n",
            "Epoch 20/100\n",
            "379/379 [==============================] - 0s 64us/step - loss: 0.0358 - val_loss: 0.1526\n",
            "Epoch 21/100\n",
            "379/379 [==============================] - 0s 61us/step - loss: 0.0361 - val_loss: 0.1571\n",
            "Epoch 22/100\n",
            "379/379 [==============================] - 0s 81us/step - loss: 0.0377 - val_loss: 0.1588\n",
            "Epoch 23/100\n",
            "379/379 [==============================] - 0s 61us/step - loss: 0.0355 - val_loss: 0.1545\n",
            "Epoch 24/100\n",
            "379/379 [==============================] - 0s 69us/step - loss: 0.0358 - val_loss: 0.1516\n",
            "Epoch 25/100\n",
            "379/379 [==============================] - 0s 51us/step - loss: 0.0356 - val_loss: 0.1583\n",
            "Epoch 26/100\n",
            "379/379 [==============================] - 0s 64us/step - loss: 0.0341 - val_loss: 0.1580\n",
            "Epoch 27/100\n",
            "379/379 [==============================] - 0s 49us/step - loss: 0.0363 - val_loss: 0.1526\n",
            "Epoch 28/100\n",
            "379/379 [==============================] - 0s 57us/step - loss: 0.0335 - val_loss: 0.1730\n",
            "Epoch 29/100\n",
            "379/379 [==============================] - 0s 61us/step - loss: 0.0346 - val_loss: 0.1674\n",
            "Epoch 30/100\n",
            "379/379 [==============================] - 0s 55us/step - loss: 0.0346 - val_loss: 0.1612\n",
            "Epoch 31/100\n",
            "379/379 [==============================] - 0s 69us/step - loss: 0.0336 - val_loss: 0.1593\n",
            "Epoch 32/100\n",
            "379/379 [==============================] - 0s 60us/step - loss: 0.0346 - val_loss: 0.1622\n",
            "Epoch 33/100\n",
            "379/379 [==============================] - 0s 69us/step - loss: 0.0333 - val_loss: 0.1521\n",
            "Epoch 34/100\n",
            "379/379 [==============================] - 0s 53us/step - loss: 0.0347 - val_loss: 0.1624\n",
            "Epoch 35/100\n",
            "379/379 [==============================] - 0s 54us/step - loss: 0.0329 - val_loss: 0.1555\n",
            "Epoch 36/100\n",
            "379/379 [==============================] - 0s 66us/step - loss: 0.0325 - val_loss: 0.1629\n",
            "Epoch 37/100\n",
            "379/379 [==============================] - 0s 57us/step - loss: 0.0319 - val_loss: 0.1605\n",
            "Epoch 38/100\n",
            "379/379 [==============================] - 0s 59us/step - loss: 0.0323 - val_loss: 0.1590\n",
            "Epoch 39/100\n",
            "379/379 [==============================] - 0s 67us/step - loss: 0.0327 - val_loss: 0.1627\n",
            "Epoch 40/100\n",
            "379/379 [==============================] - 0s 58us/step - loss: 0.0327 - val_loss: 0.1529\n",
            "Epoch 41/100\n",
            "379/379 [==============================] - 0s 70us/step - loss: 0.0319 - val_loss: 0.1708\n",
            "Epoch 42/100\n",
            "379/379 [==============================] - 0s 56us/step - loss: 0.0332 - val_loss: 0.1575\n",
            "Epoch 43/100\n",
            "379/379 [==============================] - 0s 61us/step - loss: 0.0317 - val_loss: 0.1695\n",
            "Epoch 44/100\n",
            "379/379 [==============================] - 0s 55us/step - loss: 0.0316 - val_loss: 0.1611\n",
            "Epoch 45/100\n",
            "379/379 [==============================] - 0s 61us/step - loss: 0.0315 - val_loss: 0.1579\n",
            "Epoch 46/100\n",
            "379/379 [==============================] - 0s 63us/step - loss: 0.0307 - val_loss: 0.1638\n",
            "Epoch 47/100\n",
            "379/379 [==============================] - 0s 66us/step - loss: 0.0313 - val_loss: 0.1605\n",
            "Epoch 48/100\n",
            "379/379 [==============================] - 0s 54us/step - loss: 0.0326 - val_loss: 0.1632\n",
            "Epoch 49/100\n",
            "379/379 [==============================] - 0s 59us/step - loss: 0.0304 - val_loss: 0.1576\n",
            "Epoch 50/100\n",
            "379/379 [==============================] - 0s 58us/step - loss: 0.0305 - val_loss: 0.1560\n",
            "Epoch 51/100\n",
            "379/379 [==============================] - 0s 73us/step - loss: 0.0293 - val_loss: 0.1718\n",
            "Epoch 52/100\n",
            "379/379 [==============================] - 0s 52us/step - loss: 0.0303 - val_loss: 0.1577\n",
            "Epoch 53/100\n",
            "379/379 [==============================] - 0s 71us/step - loss: 0.0311 - val_loss: 0.1691\n",
            "Epoch 54/100\n",
            "379/379 [==============================] - 0s 48us/step - loss: 0.0288 - val_loss: 0.1571\n",
            "Epoch 55/100\n",
            "379/379 [==============================] - 0s 57us/step - loss: 0.0291 - val_loss: 0.1667\n",
            "Epoch 56/100\n",
            "379/379 [==============================] - 0s 58us/step - loss: 0.0312 - val_loss: 0.1661\n",
            "Epoch 57/100\n",
            "379/379 [==============================] - 0s 63us/step - loss: 0.0280 - val_loss: 0.1643\n",
            "Epoch 58/100\n",
            "379/379 [==============================] - 0s 61us/step - loss: 0.0273 - val_loss: 0.1612\n",
            "Epoch 59/100\n",
            "379/379 [==============================] - 0s 50us/step - loss: 0.0309 - val_loss: 0.1693\n",
            "Epoch 60/100\n",
            "379/379 [==============================] - 0s 49us/step - loss: 0.0286 - val_loss: 0.1651\n",
            "Epoch 61/100\n",
            "379/379 [==============================] - 0s 71us/step - loss: 0.0300 - val_loss: 0.1659\n",
            "Epoch 62/100\n",
            "379/379 [==============================] - 0s 56us/step - loss: 0.0276 - val_loss: 0.1747\n",
            "Epoch 63/100\n",
            "379/379 [==============================] - 0s 48us/step - loss: 0.0289 - val_loss: 0.1632\n",
            "Epoch 64/100\n",
            "379/379 [==============================] - 0s 57us/step - loss: 0.0264 - val_loss: 0.1743\n",
            "Epoch 65/100\n",
            "379/379 [==============================] - 0s 45us/step - loss: 0.0274 - val_loss: 0.1714\n",
            "Epoch 66/100\n",
            "379/379 [==============================] - 0s 51us/step - loss: 0.0281 - val_loss: 0.1636\n",
            "Epoch 67/100\n",
            "379/379 [==============================] - 0s 45us/step - loss: 0.0278 - val_loss: 0.1704\n",
            "Epoch 68/100\n",
            "379/379 [==============================] - 0s 47us/step - loss: 0.0271 - val_loss: 0.1727\n",
            "Epoch 69/100\n",
            "379/379 [==============================] - 0s 61us/step - loss: 0.0279 - val_loss: 0.1645\n",
            "Epoch 70/100\n",
            "379/379 [==============================] - 0s 52us/step - loss: 0.0280 - val_loss: 0.1841\n",
            "Epoch 71/100\n",
            "379/379 [==============================] - 0s 46us/step - loss: 0.0262 - val_loss: 0.1698\n",
            "Epoch 72/100\n",
            "379/379 [==============================] - 0s 46us/step - loss: 0.0266 - val_loss: 0.1723\n",
            "Epoch 73/100\n",
            "379/379 [==============================] - 0s 44us/step - loss: 0.0263 - val_loss: 0.1780\n",
            "Epoch 74/100\n",
            "379/379 [==============================] - 0s 45us/step - loss: 0.0255 - val_loss: 0.1721\n",
            "Epoch 75/100\n",
            "379/379 [==============================] - 0s 67us/step - loss: 0.0257 - val_loss: 0.1637\n",
            "Epoch 76/100\n",
            "379/379 [==============================] - 0s 48us/step - loss: 0.0272 - val_loss: 0.1736\n",
            "Epoch 77/100\n",
            "379/379 [==============================] - 0s 50us/step - loss: 0.0253 - val_loss: 0.1701\n",
            "Epoch 78/100\n",
            "379/379 [==============================] - 0s 52us/step - loss: 0.0266 - val_loss: 0.1680\n",
            "Epoch 79/100\n",
            "379/379 [==============================] - 0s 51us/step - loss: 0.0266 - val_loss: 0.1651\n",
            "Epoch 80/100\n",
            "379/379 [==============================] - 0s 58us/step - loss: 0.0252 - val_loss: 0.1742\n",
            "Epoch 81/100\n",
            "379/379 [==============================] - 0s 54us/step - loss: 0.0254 - val_loss: 0.1660\n",
            "Epoch 82/100\n",
            "379/379 [==============================] - 0s 43us/step - loss: 0.0248 - val_loss: 0.1661\n",
            "Epoch 83/100\n",
            "379/379 [==============================] - 0s 68us/step - loss: 0.0239 - val_loss: 0.1785\n",
            "Epoch 84/100\n",
            "379/379 [==============================] - 0s 52us/step - loss: 0.0258 - val_loss: 0.1835\n",
            "Epoch 85/100\n",
            "379/379 [==============================] - 0s 60us/step - loss: 0.0261 - val_loss: 0.1784\n",
            "Epoch 86/100\n",
            "379/379 [==============================] - 0s 54us/step - loss: 0.0248 - val_loss: 0.1672\n",
            "Epoch 87/100\n",
            "379/379 [==============================] - 0s 64us/step - loss: 0.0233 - val_loss: 0.1641\n",
            "Epoch 88/100\n",
            "379/379 [==============================] - 0s 55us/step - loss: 0.0240 - val_loss: 0.1676\n",
            "Epoch 89/100\n",
            "379/379 [==============================] - 0s 63us/step - loss: 0.0249 - val_loss: 0.1825\n",
            "Epoch 90/100\n",
            "379/379 [==============================] - 0s 61us/step - loss: 0.0241 - val_loss: 0.1982\n",
            "Epoch 91/100\n",
            "379/379 [==============================] - 0s 86us/step - loss: 0.0254 - val_loss: 0.1706\n",
            "Epoch 92/100\n",
            "379/379 [==============================] - 0s 82us/step - loss: 0.0234 - val_loss: 0.1742\n",
            "Epoch 93/100\n",
            "379/379 [==============================] - 0s 51us/step - loss: 0.0232 - val_loss: 0.1745\n",
            "Epoch 94/100\n",
            "379/379 [==============================] - 0s 50us/step - loss: 0.0232 - val_loss: 0.1738\n",
            "Epoch 95/100\n",
            "379/379 [==============================] - 0s 55us/step - loss: 0.0250 - val_loss: 0.1786\n",
            "Epoch 96/100\n",
            "379/379 [==============================] - 0s 52us/step - loss: 0.0240 - val_loss: 0.1802\n",
            "Epoch 97/100\n",
            "379/379 [==============================] - 0s 66us/step - loss: 0.0233 - val_loss: 0.1858\n",
            "Epoch 98/100\n",
            "379/379 [==============================] - 0s 53us/step - loss: 0.0226 - val_loss: 0.1777\n",
            "Epoch 99/100\n",
            "379/379 [==============================] - 0s 56us/step - loss: 0.0243 - val_loss: 0.1772\n",
            "Epoch 100/100\n",
            "379/379 [==============================] - 0s 55us/step - loss: 0.0235 - val_loss: 0.1739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIJa2TVYwj8I",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Brs6eowmsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7e6bbf78-5c88-4fba-d2f2-e6ef01bbad5d"
      },
      "source": [
        "#YOUR CODE HERE - Evaluate the model on testing data. The model will return loss value and metrics.\n",
        "mse = model.evaluate(x_test, y_test)\n",
        "#YOUR CODE HERE - Compute and print the RMSE (aka square root of MSE)\n",
        "print(f\"Mean Square Root is: {np.sqrt(mse)}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127/127 [==============================] - 0s 49us/step\n",
            "Mean Square Root is: 0.4169646357092339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLBkrqB7Ty9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}